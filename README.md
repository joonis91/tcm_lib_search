## 한의학 고전 문헌에서,처방전(방제,fangzi)을 추출해서 데이터베이스로 구축하고 검색하는 프로그래밍에 대해서.

### 1. 서론

본 보고서는 전통 중의학(Traditional Chinese Medicine, TCM) 고전문헌을 분석하여 처방 정보를 추출하고, 이를 효율적으로 검색 및 관리하기 위해 개발된 시스템의 핵심 기술을 심층적으로 분석합니다. 특히, 제공된 Python 스크립트(`extract_formula.py`, `m01_HerbCheck.py`, `m02_herb_classifier.py`, `m03_article_tokenizer.py`, `m04_formula_extractor.py`)와 SQLite 데이터베이스 구조를 기반으로, 데이터 전처리, 자연어 처리(NLP)를 이용한 단어 분리, 머신러닝 기반의 처방 가능성 예측, 처방 인식 및 원문 조각 추출 과정을 상세히 설명합니다. 또한, 데이터베이스 구조와 한약재 사전 정보의 변환 과정도 함께 다룹니다.

### 2. 시스템 개요

본 시스템은 중의학 고전문헌 텍스트 파일을 입력으로 받아, 1) 문장 토큰화, 2) 토큰의 품사 태깅 및 한약재 여부 판단, 3) 머신러닝 기반의 처방 가능성 점수 예측, 4) 연속된 한약재 시퀀스 기반의 처방 추출, 5) 추출된 처방 주변의 원문 조각(snippet) 수집 과정을 거쳐, TCM 처방 정보를 SQLite 데이터베이스에 저장합니다. 사용자는 웹 인터페이스(`index.php`)를 통해 데이터베이스를 검색하고 상세 정보를 확인할 수 있습니다.

### 3. 기술 스택

* **Python >= 3.5:** 핵심 데이터 처리 및 머신러닝 로직 구현
* **jieba:** 중국어 텍스트 토큰화 및 품사 태깅을 위한 오픈소스 라이브러리
* **scikit-learn (sklearn) >= 0.19:** 한약재 식별 가능성 분류를 위한 머신러닝 모델 학습 및 예측
* **pandas >= 0.18:** 데이터 전처리 및 중간 데이터 관리를 위한 라이브러리
* **numpy >= 1.13:** 수치 계산 및 배열 처리를 위한 라이브러리
* **SQLite:** 추출된 처방 정보 및 관련 메타데이터 저장
* **PHP:** 웹 인터페이스 구축 및 데이터베이스 연동 (`index.php`, `fetch_snippet.php`)

### 4. 데이터베이스 구조 (`metadata.sqlite`)

 `metadata.sqlite` 데이터베이스는 다음과 같은 테이블 구조를 가집니다.

* **`fangzi` 테이블:방제**
    * `id` (INTEGER PRIMARY KEY): 처방 고유 식별자 (1개의 처방식별자에 여러개의 약재들이 배당됨)
    * `herb` (TEXT): 해당 처방에 사용된 약재 목록 (쉼표로 구분)
* **`fangzi_article` 테이블:방제의 출전**
    * `fangzi_id` (INTEGER): `fangzi` 테이블의 `id` 참조 (외래 키)
    * `article` (TEXT): 처방이 기록된 원문 파일 경로 또는 이름(출처)
    * `start_pos` (INTEGER): 원문에서 해당 처방이 시작되는 문자 위치
    * `end_pos` (INTEGER): 원문에서 해당 처방이 끝나는 문자 위치
* **`fangzi_snippets` 테이블:방제가 들어있는 원원문조각들**
    * `fangzi_id` (INTEGER): `fangzi` 테이블의 `id` 참조 (외래 키)
    * `snippet` (TEXT): 해당 처방 주변의 원문 조각. 약재들의 목록에서부터, 앞에 30글자, 뒤에 30글자를 추출해서 기록한다.
    * `fangzi_name` (TEXT): 처방 이름 (미완성. 처방이름을 추출해서 넣으려고 했으나 미완성)
    * `fangzi_origin` (TEXT): 처방 출처 (미완성. 처방이 나온 문헌의 이름을 넣으려고 했으나 미완성)

### 5. 데이터 변환 및 전처리

원본 데이터 및 한약재 사전 정보는 중국어 간자체와 번자체가 혼용되어 있으므로, 한국어 사용자가 이해하기 쉽도록 **중국어 번자체 (고전 한문)** 로 변환되었습니다. 이 변환 과정은 시스템 구축 이전에 수행되었으며, 변환된 데이터가 시스템의 입력으로 사용됩니다.

### 6. 핵심 기술 상세 분석

#### 6.1. 중국어 텍스트 토큰화 (`m03_article_tokenizer.py`)

* **jieba 활용:** 중국어는 단어 사이에 공백이 없어, 의미 있는 단위로 분리하는 것이 중요합니다. 본 시스템은 **jieba**라는 파이썬 오픈소스 라이브러리를 사용하여 이 작업을 수행합니다. jieba는 사전 기반 및 통계 모델을 결합하여 높은 정확도로 중국어 문장을 단어(토큰) 단위로 분리합니다.
* **사용자 사전 로딩:** `jieba.load_userdict(herb_file)` 코드를 통해 `common_herbs.txt` 파일에 정의된 한약재 어휘 목록을 jieba의 사용자 사전으로 로드합니다. 이는 jieba가 한약재 용어를 하나의 의미 있는 토큰으로 인식하도록 돕습니다.
* **품사 태깅:** `jieba.posseg.cut(text, HMM=False)` 함수는 토큰화된 각 단어에 품사 태그를 부착합니다. 이 품사 정보는 후속 단계에서 한약재 식별 및 처방 패턴 분석에 활용될 수 있습니다.
* **토큰 위치 정보:** 원문 텍스트 내에서 각 토큰의 시작 위치를 `token_indexes` 리스트에 저장합니다. 이는 나중에 처방의 위치를 파악하고 원문 조각을 추출하는 데 사용됩니다.

#### 6.2. 한약재 식별 (`m01_HerbCheck.py`, `m03_article_tokenizer.py`)

* **`HerbChecker` 클래스:** `m01_HerbCheck.py`에 정의된 `HerbChecker` 클래스는 주어진 토큰이 한약재인지 여부를 판단하는 기능을 제공합니다.
    * **사전 기반 확인:** `common_herbs.txt` 파일을 읽어와 구축한 `common_herbs_set`을 사용하여 토큰이 사전에 존재하는지 직접 비교합니다.
    * **부분 문자열 검색:** 토큰의 길이가 2 이상인 경우, 토큰 내에 사전에 등록된 한약재 이름이 포함되어 있는지 확인합니다 (예: "당귀尾"에서 "당귀"를 인식).
    * **역색인 활용:** 한약재 이름의 첫 글자를 기준으로 역색인을 구축하여 검색 효율성을 높입니다.
* **통계적 분류 (`m02_herb_classifier.py`, `m03_article_tokenizer.py`):** 단순 사전 기반 매칭 외에도, 주변 단어의 품사 정보, 특정 지시어(‘宜’, ‘用’, ‘加’, ‘汤’, ‘散’ 등) 등장 여부, 주변 한약재 밀도 등 다양한 **문맥적 특징(contextual features)** 을 추출하여, **scikit-learn** 라이브러리의 머신러닝 모델(`logisticreg-penaltyl1-C1.0.pkl`, 로지스틱 회귀 모델)을 사용하여 토큰이 한약재일 확률을 예측합니다.
    * `m02_herb_classifier.py`는 특징 선택 및 변환을 위한 클래스들을 정의합니다.
    * `m03_article_tokenizer.py`의 `tokenize_article` 함수 내에서 주변 단어의 품사, 특정 지시어 등장 여부 등을 특징으로 추출하고, 학습된 `herb_token_classifier` 모델의 `predict_proba` 메소드를 사용하여 각 토큰이 한약재일 확률(`herb_probs`)을 계산합니다.

#### 6.3. 처방 추출 (`m04_formula_extractor.py`)

* **연속된 한약재 시퀀스 인식:** `extract_fangzi` 함수는 토큰화 및 한약재 확률 예측 결과를 바탕으로, 원문 내에서 **3개 이상 연속적으로 나타나는 한약재 시퀀스**를 하나의 처방으로 인식합니다. 이때, 한약재 토큰 사이의 비-한약재 토큰의 최대 허용 개수(`max_sep`)를 설정하여, 너무 멀리 떨어진 약재들을 하나의 처방으로 인식하는 것을 방지합니다.
* **처방 경계 및 위치 정보:** 처방으로 인식된 연속된 한약재 시퀀스의 시작 토큰과 끝 토큰의 원문 위치(`token_indexes`)를 기록하여, 해당 처방의 원문 `start_pos` 와 `end_pos` 를 `fangzi_article` 테이블에 저장합니다.
* **약재 이름 정제:** 추출된 처방 내의 약재 이름에서 불필요한 접미사('方', '散', '剂', '丸', '汤')를 제거하고 중복된 약재를 제거합니다.

#### 6.4. 원문 조각 (Snippet) 추출 (`m04_formula_extractor.py` )

* **`extract_fangzi`:** 처방이 추출될 때, 해당 처방의 위치 정보를 활용하여 주변 원문을 수집합니다. `extract_formula.py`의 `if args.print_original_text:` 블록에서 처방 시작 위치로부터 앞뒤 30글자씩을 추출하는 것을 예시로 볼 수 있습니다.

#### 6.5. 웹호스팅 사이트에 올려서, 인터넷에서 데이터베이스에 접속해서 검색할수 있는 기능 구현 (`index.php`, `fetch_snippet.php`)

* **`index.php`:** 웹 페이지에서 검색 결과를 표시할 때, 각 처방 ID를 기반으로 `fetch_snippet.php`를 비동기적으로 호출하여 해당 처방의 약재, 출처, 원문 조각 정보를 JSON 형태로 가져와 화면에 표시합니다.
* **`fetch_snippet.php`:** 특정 `fangzi_id`를 받아서 데이터베이스에서 해당 처방의 약재 목록 (`fangzi` 테이블), 출처 (`fangzi_article` 테이블의 `article` 컬럼의 파일명), 그리고 원문 조각 (`fangzi_snippets` 테이블의 `snippet` 컬럼)을 조회하여 JSON 형식으로 반환합니다.

* 데이터 수정기능 추가

#### 6.6. 머신러닝 기반 처방 가능성 분석

`m03_article_tokenizer.py`에서 각 토큰에 대해 한약재일 확률을 예측하는 과정은, 해당 토큰이 처방을 구성하는 핵심 요소일 가능성을 간접적으로 평가하는 단계로 볼 수 있습니다. 3개 이상의 연속된 토큰이 높은 한약재 확률을 가질 경우, `m04_formula_extractor.py`는 이를 처방으로 인식하는 로직을 구현합니다. 즉, **머신러닝 모델의 예측 결과가 처방 추출 규칙의 중요한 판단 근거**로 활용됩니다.

### 7. 결론

본 보고서는 중의학 고전문헌 분석 및 TCM 처방 정보 추출 시스템의 핵심 기술들을 상세히 설명했습니다. **jieba**를 이용한 정확한 토큰화, **scikit-learn** 기반의 통계적 한약재 식별, 그리고 연속된 한약재 시퀀스 인식을 통한 처방 추출은 본 시스템의 핵심 기술입니다. 추출된 처방 정보는 SQLite 데이터베이스에 체계적으로 저장되며, 웹 인터페이스를 통해 사용자에게 효율적으로 제공됩니다. 향후 시스템 개선을 위해서는 더욱 정교한 처방 인식 규칙 개발, 다양한 유형의 처방 패턴 학습, 그리고 의미 기반 검색 기능 도입 등이 고려될 수 있습니다.

******

실제 사용해 본 경험으로는, 지금은 9년전에 이 기술이 나왔을때보다 컴퓨터의 성능이 많이 향상되고 속도가 빨라져서 , 굳이 이런 방법까지 쓸 필요는 없는것 같습니다. 또한, 이 방식으로 추출된 데이터의 정확도 및 신뢰도가 그렇게 높지 않아서(빼먹거나 제외되는 약재 데이터들이 많았습니다.), 약재들을 몇가지 넣어서 처방명 및 문헌정보를 찾는 기술은 이것을 쓸 필요는 없어보입니다.  요즘은 문헌 텍스트 자체들을 상당히 잘 정제해서 만들기 때문에, 그냥 문헌 텍스트 자체를 통째로 데이터베이스에 넣어서, 수많은 문헌들을 줄 단위로 검색하면, 같은 행에 있는 복수의 약재들을 검색해내는 것이 별로 어렵지 않기 때문입니다.  
 더군다나, 최근 급격하게 발전하고 있는 "자연어 기반의 인공지능 시스템(AI LLM model)" 들에게 문서들을 통째로 수천개를 먹여준 다음에,  그중에서 특정한 처방들을 추출해서 새로운 문서로 만들고 정리해달라고 한다거나, 특정 질환들에 효과적인 처방들을 추출해서, 안전하고 효과적인 처방들 순서대로 뽑아달라고 하는 일들은 이제 충분히 가능한 시대가 되었습니다. 
  하지만, 중국에서 자국어로 된 고문헌을 분석하고 그중에서 약재들을 모아놓은 문구 덩어리들을 추출하고 데이터베이스화 하기 위해서 어떠한 노력을 했는지를 살펴보는 것은 무척 의미있는 일이었습니다. 


-----

이렇게 만들어진 "metadata.sqlite" 데이터베이스를 저는 모두 전통 한문(중국어 번자체)로 변환하였고, 이를 활용해서 웹에서 접근해서 검색하기 좋은 형태로 변환하는 프로젝트를 진행을 했습니다.  해당 데이터베이스는 원 저작자인  https://github.com/wang-shuyu/tcm_lib_search  (wang-shuyu ) 님의 페이지에서 다운로드 받을수 있었습니다.  기타 자세한 내용은 원작자의 해당 페이지에서 확인하시기 바랍니다. 

 * 해당 원작자 홈페이지에서 다운로드 받아서, 제가 고전 한문(중국어 번체자)으로 변환한 데이터베이스는  https://drive.google.com/file/d/1O1o3kE9WipB7kn4438Ad_xFhrrE2NVg1/view?usp=drive_link  에서 다운로드 받으실수 있습니다.
 *  원작자가 만든 한약재 사전 파일은 여기에 첨부해 두었습니다.  (역시 간자체를 번자체로 변환함)

   --------------------------------
 ## 참고자료 : 한문으로 이루어진 고문헌의 자료수집, 텍스트 분석 및 전처리, 데이터베이스화 하는 과정 ##

 옛날 한의학 서적을 분석하여 **처방명과 처방내용을 추출하고 데이터베이스화**하는 과정은 여러 단계로 이루어집니다. 이를 위해 **텍스트 처리, 자연어 처리(NLP), 데이터베이스 구축** 등의 기술 스택을 활용해야 합니다. 🚀  

---

### **📌 1. 데이터 수집 및 전처리**
#### **✅ 기술 스택:** `Python`, `BeautifulSoup`, `PDFMiner`, `OCR (Tesseract)`
1️⃣ **문헌 수집**  
   - 한의학 서적은 **PDF, 이미지, HTML, 텍스트 파일** 형태로 존재할 수 있음.  
   - 웹에서 크롤링(`BeautifulSoup`)을 통해 문헌을 수집하거나, 직접 스캔하여 OCR을 적용할 수도 있음.  

2️⃣ **OCR을 통한 텍스트 변환**  
   - 이미지 기반 문헌은 **Tesseract OCR**을 사용하여 텍스트로 변환.  
   - PDF 파일은 **PDFMiner**를 활용하여 텍스트를 추출.  

3️⃣ **텍스트 정제 및 전처리**  
   - 불필요한 공백, 특수문자 제거 (`re` 라이브러리 활용).  
   - 한자와 한글이 섞여 있는 경우, **한자만 추출**하는 필터링 적용.  

---

### **📌 2. 처방명 및 처방내용 추출**
#### **✅ 기술 스택:** `Jieba`, `SpaCy`, `NLTK`, `Regex`
1️⃣ **텍스트 토큰화 및 형태소 분석**  
   - **Jieba**를 사용하여 중국어 문장을 단어 단위로 분리.  
   - **SpaCy** 또는 **NLTK**를 활용하여 처방명과 처방내용을 추출.  

2️⃣ **처방명과 처방내용을 구분하는 규칙 설정**  
   - 일반적으로 처방명은 **특정 패턴**을 따름 (`XX汤`, `XX散`, `XX丸` 등).  
   - **정규식(Regex)**을 활용하여 처방명을 자동으로 추출.  

3️⃣ **처방내용 추출**  
   - 처방명 다음에 오는 **약재 목록 및 용량**을 추출.  
   - **NER (Named Entity Recognition)**을 활용하여 약재 이름을 식별.  

---

### **📌 3. 데이터베이스 구축**
#### **✅ 기술 스택:** `SQLite`, `MySQL`, `PostgreSQL`
1️⃣ **데이터베이스 스키마 설계**  
   - `prescriptions` 테이블을 생성하여 **처방명과 처방내용을 저장**.  
   - 예제 테이블 구조:
     ```sql
     CREATE TABLE prescriptions (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         name TEXT NOT NULL,
         ingredients TEXT NOT NULL
     );
     ```

2️⃣ **데이터 삽입 및 검색 최적화**  
   - **FULLTEXT 인덱스**를 활용하여 빠른 검색 지원.  
   - 예제:
     ```sql
     CREATE INDEX idx_prescriptions ON prescriptions(name);
     ```

---

### **📌 4. 검색 및 활용**
#### **✅ 기술 스택:** `FastAPI`, `Elasticsearch`, `Flask`
1️⃣ **API 개발**  
   - **FastAPI** 또는 **Flask**를 사용하여 검색 API 구축.  
   - 예제:
     ```python
     from flask import Flask, request
     import sqlite3

     app = Flask(__name__)

     @app.route('/search')
     def search():
         query = request.args.get('q')
         conn = sqlite3.connect("data/prescriptions.db")
         cursor = conn.cursor()
         cursor.execute("SELECT * FROM prescriptions WHERE name LIKE ?", (f"%{query}%",))
         results = cursor.fetchall()
         conn.close()
         return {"results": results}

     if __name__ == "__main__":
         app.run(debug=True)
     ```

2️⃣ **Elasticsearch를 활용한 고급 검색**  
   - **자연어 검색**을 지원하여 유사한 처방을 추천.  
   - **키워드 기반 검색**을 통해 특정 약재가 포함된 처방을 찾을 수 있도록 설정.  

---

### **🚀 최종 요약**
✅ **데이터 수집** → OCR 및 크롤링을 통해 문헌을 확보  
✅ **텍스트 전처리** → 한자 필터링 및 정제  
✅ **처방명 및 처방내용 추출** → NLP 및 정규식을 활용  
✅ **데이터베이스 구축** → SQLite 또는 MySQL을 사용하여 저장  
✅ **검색 및 활용** → API 및 Elasticsearch를 통해 검색 기능 제공  

이제 이 과정을 따라가면 **옛날 한의학 서적을 분석하여 처방 데이터베이스를 구축**할 수 있어요! 🚀  
추가적인 기능이 필요하면 언제든지 알려주세요. 😊


 
[common_herbs.txt](https://github.com/user-attachments/files/19824170/common_herbs.txt)
